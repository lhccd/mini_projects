{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSS_SemanticDrift_lorenz.ipynb",
      "provenance": [],
      "mount_file_id": "1h756aZJHq2FjPVacQ74fjrl72WqvVwkW",
      "authorship_tag": "ABX9TyNv+TfyDGbfZNnqu0pcBu3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhccd/mini_projects/blob/main/CSS_SemanticDrift_lorenz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aKaedB5iPE8J"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ukraine_jan_2013_to_jan_2016.json', 'r') as f:\n",
        "  data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"\"\n",
        "\n",
        "for tweet in data: \n",
        "  txt = txt + tweet[\"tweet_text\"]\n",
        "\n",
        "print(txt[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHuL4jwpPYFc",
        "outputId": "cf4e4f45-c478-4af0-9b5c-867feeb69ee7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"I CAN ONLY SAY UKRAINE THIS IS YOUR LAND AND YOUR PEOPLE SO DEAL WITH RUSSIA LIKE YOU WOULD DEAL WITH A BUSINESS... https://t.co/kP2MUpnv2OBetrayal or Victory: what did 2015 bring for #Ukraine? \n",
            "https://t.co/jg50T2qVGj https://t.co/zLs07uOh9J#Lviv Jan 01 01:30 Temperature -13C cloudless, Haze Humidity 90% Ukraine .. https://t.co/6HvshVbRMuUkraine: Russia hacking power plants, highlighting U.S. weakness https://t.co/qUha2LNN3L@USEmbRu The best solution to the problems of Ukraine#60dc2 #60dc How To Celebrate Ukraine New Year's Traditions For 20 Days https://t.co/ybMSBdtXiOUkrainian economy in ruins after neocon coup. Where's State Mama Nudelman with her free cookies now? asked W Madsen\n",
            "https://t.co/Sx5OTbmzwLRussia and Ukraine Finally Break Up - Bloomberg View https://t.co/Jc6pSbGUwmPower cuts in Crimea after new blast on Ukraine power line #power https://t.co/m4RYdGPzYM@alkapranos @B0bHardy Happy New Year from Ukraine! :) https://t.co/ixO7CXXksCHappy New Year from Ukraine ðŸŽ„ðŸŽ‰Spotlight: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform data cleaning\n",
        "## TODO: remove links/ user mentions\n",
        "\n",
        "# lower case txt\n",
        "txt = txt.lower()\n",
        "\n",
        "# remove emojis\n",
        "import re\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "txt = deEmojify(txt)"
      ],
      "metadata": {
        "id": "wnkPfqSRPahw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save text file\n",
        "\n",
        "#open text file\n",
        "text_file = open('/content/train.txt', 'w')\n",
        " \n",
        "#write string to file\n",
        "text_file.write(txt)\n",
        " \n",
        "#close file\n",
        "text_file.close()"
      ],
      "metadata": {
        "id": "4itvov4KPccH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWebnE0FVAUt",
        "outputId": "9b99c2de-40ea-445f-a6fd-e5f57d39203a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "with open('/content/train.txt', 'r') as f:\n",
        "  tweets_text = f.read()\n",
        "\n",
        "print(tweets_text[:1000])\n",
        "testset = tweets_text[:10000]\n",
        "word_tokenize(testset)"
      ],
      "metadata": {
        "id": "RRcuOpDeVKY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "\n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer"
      ],
      "metadata": {
        "id": "WYWFo-DHpjaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = ['/content/train.txt']\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "!mkdir Ukraine_ML\n",
        "tokenizer.save_model(\"Ukraine_ML\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oAuG4x4pyUR",
        "outputId": "9f8a9ddc-daec-4873-ca51-a8fbbf551197"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ukraine_ML/vocab.json', 'Ukraine_ML/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./Ukraine_ML/vocab.json\",\n",
        "    \"./Ukraine_ML/merges.txt\",\n",
        ")"
      ],
      "metadata": {
        "id": "lRvTLVFCs594"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "metadata": {
        "id": "QPQiwaXHtASL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"This is putin\").tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4afLTEWqtEVo",
        "outputId": "194af973-3222-4230-b4ee-44e4c1c8a898"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'T', 'his', 'Ä is', 'Ä putin', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Language Model"
      ],
      "metadata": {
        "id": "u-kQKzTItLIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjAfglsmtLyi",
        "outputId": "bd661fd8-0806-415b-f8ae-41f92671bea2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "metadata": {
        "id": "QjCS1ryFtQSi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}